{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import scipy.linalg as la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTHMM:\n",
    "    def __init__(self, n_states, n_dim):\n",
    "        self.n_states = n_states\n",
    "        self.log_pi = np.log(np.ones((self.n_states)) / self.n_states)\n",
    "        self.log_P = {}\n",
    "        self.n_pid = 0\n",
    "        \n",
    "        # init R\n",
    "        self.R = -np.eye(self.n_states)\n",
    "        self.R[-1, -1] = 0\n",
    "        for i in range(self.n_states - 1):\n",
    "            self.R[i,i+1:] = 1 / (self.R[i+1:].shape[0])\n",
    "        \n",
    "        self.n_dim = n_dim\n",
    "        \n",
    "        # init emission matrix\n",
    "        self.emission_matrix = np.zeros((2, self.n_states, self.n_dim))\n",
    "        self.emission_matrix[0, :, :] = 2\n",
    "        self.emission_matrix[1, :, :] = .5\n",
    "        self.emission_matrix[0, 0, :] = 4\n",
    "        self.emission_matrix[0, -1, :] = 0\n",
    "\n",
    "    def EM_step(self, data):\n",
    "        ### E Step ###\n",
    "        \n",
    "        self.n_pid = data['subject_id'].unique().shape[0]\n",
    "        \n",
    "        log_pi_update = np.zeros((self.n_states))\n",
    "        weighted_means = np.log(np.zeros((self.n_states, self.n_dim)))\n",
    "\n",
    "        unique_intervals = data['delta_t'].unique()\n",
    "        C = np.zeros((unique_intervals.shape[0], self.n_states, self.n_states))\n",
    "        interval_map = {}\n",
    "        \n",
    "        total_weight_assgn = np.log(np.zeros((self.n_states)))\n",
    "        \n",
    "        for pid, pdata in data.groupby('subject_id'):\n",
    "#             print (pdata.columns)\n",
    "            obs = pdata.drop(['subject_id', 'ALSFRS_Delta', 'delta_t', 'ALSFRS_Total'], axis=1).values\n",
    "            intervals = pdata['delta_t'].values\n",
    "\n",
    "            alpha = self.forward(obs, intervals)\n",
    "            beta = self.backward(obs, intervals)\n",
    "\n",
    "            LL = logsumexp((alpha[:, -1] + beta[:, -1]))\n",
    "            \n",
    "#             print ('Sanity:\\n', logsumexp((alpha + beta), axis=0))\n",
    "            \n",
    "            for idx, t_delta in enumerate(intervals[1:]):\n",
    "                if t_delta not in interval_map:\n",
    "                    interval_map[t_delta] = len(interval_map.keys())\n",
    "                log_P = self.log_transition_matrix(t_delta)\n",
    "                log_emission = self.log_emission(obs[idx + 1, :])\n",
    "                for src in range(self.n_states):\n",
    "                    for dest in range(self.n_states):\n",
    "                        C[interval_map[t_delta], src, dest] = logsumexp([C[interval_map[t_delta], src, dest], alpha[src, idx], log_P[src, dest],\n",
    "                                                                     beta[dest, idx + 1], log_emission[dest]])\n",
    "\n",
    "            log_pi_update = logsumexp([log_pi_update, alpha[:, 0] + beta[:, 0] - LL], axis=0)\n",
    "#             print ('alpha:\\n', alpha)\n",
    "#             print ('beta:\\n', beta)\n",
    "#             print ('LL:\\n', LL)\n",
    "#             print ('mean update:\\n', np.e**(alpha + beta - LL) @ obs)\n",
    "            log_weights = np.zeros(alpha.shape)\n",
    "            for t in range(log_weights.shape[1]):\n",
    "                log_weights[:,t] = alpha[:,t] + beta[:,t] - logsumexp(alpha[:,t] + beta[:,t])  # M x T\n",
    "#             print ('Resp:\\n', np.sum(np.exp(log_weights), axis=0))\n",
    "#             print ('log_weights before:\\n', log_weights)\n",
    "#             print ('log_weights e sum:\\n', np.sum(np.exp(log_weights), axis=1))\n",
    "            for i in range(self.n_states):\n",
    "                for t in range(log_weights.shape[1]):\n",
    "                    for d in range(self.n_dim):\n",
    "#                         print ('weighted_prev:\\n', weighted_means[i,d])\n",
    "#                         print ('obs:\\n', obs[t,d])\n",
    "#                         print ('adding:\\n', log_weights[i,t] + np.log(obs[t,d]))\n",
    "#                         print ('logsumexp:\\n', logsumexp([weighted_means[i,d], log_weights[i,t] + np.log(obs[t,d])]))\n",
    "                        weighted_means[i, d] = logsumexp([weighted_means[i,d], log_weights[i,t] + np.log(obs[t,d])])\n",
    "                    total_weight_assgn[i] = logsumexp([total_weight_assgn[i], log_weights[i,t]])\n",
    "#                     weighted_means[i, j] = np.e**(alpha + beta - LL) @ obs\n",
    "\n",
    "\n",
    "        ### M Step ###\n",
    "\n",
    "        # Update emission params\n",
    "        self.emission_matrix[0, 1:-1, :] = np.e**(weighted_means - total_weight_assgn[:, None])[1:-1, :]\n",
    "#         self.emission_matrix[0, 1:-1, :] = np.e**(weighted_means)[1:-1, :]\n",
    "        print ('total_weight_assgn:\\n', np.e**total_weight_assgn)\n",
    "\n",
    "        # Update pi\n",
    "        self.log_pi = log_pi_update - logsumexp(log_pi_update)\n",
    "\n",
    "        # Updated R\n",
    "        A = np.zeros((self.n_states * 2, self.n_states * 2))\n",
    "        A[:self.n_states, :self.n_states] = self.R\n",
    "        A[self.n_states:, self.n_states:] = self.R\n",
    "\n",
    "        D = np.zeros((self.n_states, self.n_states, self.n_states))\n",
    "        tau = np.zeros((self.n_states))\n",
    "\n",
    "        N = np.zeros((self.n_states, self.n_states, self.n_states, self.n_states))\n",
    "        nu = np.zeros((self.n_states, self.n_states))\n",
    "        \n",
    "        C = np.e**(C) - 1\n",
    "        \n",
    "#         print('past groupby')\n",
    "#         print (interval_map)\n",
    "        for i in range(self.n_states):\n",
    "            A[i, self.n_states + i] = 1\n",
    "            for t_delta in unique_intervals:\n",
    "                if t_delta == 0:\n",
    "                    continue\n",
    "#                 print ('A exp:\\n', la.expm(A * t_delta)[:self.n_states, self.n_states:])\n",
    "#                 print ('e trans:\\n',np.e**(self.log_transition_matrix(t_delta)))\n",
    "#                 exit(0)\n",
    "                D[i] = la.expm(A * t_delta)[:self.n_states, self.n_states:] /                           \\\n",
    "                       np.e**(self.log_transition_matrix(t_delta))\n",
    "                D = np.nan_to_num(D)\n",
    "                tau[i] += np.sum(C[interval_map[t_delta], :, :] * D[i, :, :])\n",
    "            A[i, self.n_states + i] = 0\n",
    "\n",
    "        for i in range(self.n_states):\n",
    "            for j in range(self.n_states):\n",
    "                A[i, self.n_states + j] = 1\n",
    "                for t_delta in unique_intervals:\n",
    "                    if t_delta == 0:\n",
    "                        continue\n",
    "                    N[i, j] = self.R[i, j] * la.expm(A * t_delta)[:self.n_states, self.n_states:] /        \\\n",
    "                           np.e**(self.log_transition_matrix(t_delta))\n",
    "                    N = np.nan_to_num(N)\n",
    "                    nu[i, j] += np.sum(C[interval_map[t_delta], :, :] * N[i, j, :, :])\n",
    "                A[i, self.n_states + j] = 0\n",
    "#         print ('C:\\n', C)\n",
    "#         print ('D:\\n', D)\n",
    "#         print('nu:\\n',nu)\n",
    "#         print ('tau:\\n',tau)\n",
    "        \n",
    "        for i in range(self.n_states):\n",
    "            self.R[i, i+1:] = nu[i, i+1:] / tau[i]\n",
    "            self.R[i, i] = -np.sum(self.R[i, i+1:])\n",
    "            \n",
    "        self.log_P = {}\n",
    "\n",
    "\n",
    "    def log_transition_matrix(self, t_delta):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            t_delta scalar\n",
    "        Output:\n",
    "            P M x M\n",
    "        \"\"\"\n",
    "        if t_delta in self.log_P:\n",
    "            return self.log_P[t_delta]\n",
    "        \n",
    "        self.log_P[t_delta] = np.log(la.expm(self.R * t_delta))\n",
    "        \n",
    "#         print('nonlog transition:\\n', la.expm(self.R * t_delta))\n",
    "#         print('log transition:\\n', self.log_P[t_delta])\n",
    "#         print('back to nonlog:\\n', np.sum(np.e**(self.log_P[t_delta]), axis=1))\n",
    "\n",
    "        return self.log_P[t_delta]\n",
    "\n",
    "    def log_emission(self, observation):\n",
    "        \"\"\"\n",
    "            Input: D x 1\n",
    "            Output: M x 1\n",
    "        \"\"\"\n",
    "        b = np.ndarray(self.n_states, dtype=float)\n",
    "        for i in range(self.n_states):\n",
    "            means = self.emission_matrix[0, i]\n",
    "            covariance = np.diag(self.emission_matrix[1, i])\n",
    "            b[i] = multivariate_normal.logpdf(observation, means, covariance)\n",
    "        return b\n",
    "\n",
    "    def forward(self, obs, intervals):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            obs T x D\n",
    "            intervals T\n",
    "            n_states scalar\n",
    "        Output:\n",
    "            alpha M x T\n",
    "        \"\"\"\n",
    "        T = obs.shape[0]\n",
    "\n",
    "        alpha = np.zeros((self.n_states, T))\n",
    "\n",
    "#         print ('pi:\\n', self.log_pi)\n",
    "#         print ('emission:\\n', self.log_emission(obs[0,:]))\n",
    "        alpha[:, 0] = self.log_pi + self.log_emission(obs[0, :])\n",
    "        \n",
    "#         print('alpha t=0:\\n', alpha[:,0])\n",
    "\n",
    "        tmp = np.zeros((self.n_states))\n",
    "\n",
    "        for idx, t_delta in enumerate(intervals[1:]):\n",
    "            log_B = self.log_emission(obs[idx + 1, :])\n",
    "            log_P = self.log_transition_matrix(t_delta)\n",
    "            \n",
    "#             print ('transition:\\n', log_P)\n",
    "\n",
    "            for dest in range(self.n_states):\n",
    "                for src in range(self.n_states):\n",
    "                    tmp[src] = alpha[src, idx] + log_P[src, dest]\n",
    "\n",
    "                alpha[dest, idx + 1] = log_B[dest] + logsumexp(tmp)\n",
    "\n",
    "#         print ('alpha:\\n', alpha)\n",
    "        return alpha\n",
    "\n",
    "    def backward(self, observations, time_intervals):\n",
    "        T = observations.shape[0]\n",
    "        beta = np.zeros((self.n_states, T), dtype=float)\n",
    "        for t in range(T - 2, -1, -1):\n",
    "            a = self.log_transition_matrix(time_intervals[t])\n",
    "            b = self.log_emission(observations[t + 1])\n",
    "            for i in range(self.n_states):\n",
    "                beta[i, t] = logsumexp([beta[j, t + 1] + a[i, j] + b[j] for j in range(self.n_states)])\n",
    "\n",
    "#         print ('beta:\\n', beta)\n",
    "        return beta\n",
    "\n",
    "    def update_pi(self, alpha, beta):\n",
    "        self.log_pi = alpha[0, :] + beta[0, :]\n",
    "    def log_likelihood(self, data):\n",
    "        total = 0\n",
    "        for pid, pdata in data.groupby('subject_id'):\n",
    "            obs = pdata.drop(['subject_id', 'ALSFRS_Delta', 'delta_t', 'ALSFRS_Total'], axis=1).values\n",
    "            intervals = pdata['delta_t'].values\n",
    "\n",
    "            alpha = self.forward(obs, intervals)\n",
    "            total += logsumexp(alpha[-1])\n",
    "\n",
    "        return total\n",
    "\n",
    "    def save(self, filename):\n",
    "        pickle.dump(self, open(filename, 'wb'))\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, filename):\n",
    "        return pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open('model.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.CTHMM at 0x1091adf60>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.27730481, 0.26184324, 0.15800305, 0.16058716, 0.04825709,\n",
       "       0.0404989 , 0.03712102, 0.00275902, 0.01288109, 0.00074462])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(model.log_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.01, 0.02, 0.04, 0.05, 0.07, 0.1 , 0.13, 0.17, 0.4 ],\n",
       "       [0.  , 0.01, 0.02, 0.03, 0.05, 0.07, 0.1 , 0.14, 0.17, 0.41],\n",
       "       [0.  , 0.  , 0.01, 0.03, 0.05, 0.07, 0.1 , 0.14, 0.18, 0.43],\n",
       "       [0.  , 0.  , 0.  , 0.01, 0.03, 0.06, 0.1 , 0.14, 0.19, 0.46],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.02, 0.05, 0.09, 0.15, 0.19, 0.5 ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.07, 0.14, 0.2 , 0.57],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.11, 0.19, 0.67],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.15, 0.8 ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.93],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.around(la.expm(model.R * 120), decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = model.emission_matrix[0]\n",
    "variance = model.emission_matrix[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.  , 4.  , 4.  , 4.  , 4.  , 4.  , 4.  , 4.  , 4.  , 4.  ],\n",
       "       [3.8 , 3.7 , 3.86, 3.25, 2.95, 2.7 , 3.42, 2.77, 2.21, 3.73],\n",
       "       [1.43, 1.99, 2.29, 3.66, 3.57, 3.64, 3.95, 3.75, 3.46, 3.47],\n",
       "       [3.4 , 3.56, 3.61, 3.44, 3.14, 2.55, 3.06, 2.06, 0.91, 3.64],\n",
       "       [3.85, 3.92, 3.87, 3.04, 2.62, 1.45, 1.62, 1.08, 0.14, 3.66],\n",
       "       [2.83, 3.23, 3.11, 2.47, 1.57, 1.62, 2.36, 2.01, 0.62, 2.5 ],\n",
       "       [3.18, 3.55, 3.68, 0.75, 0.65, 0.7 , 1.84, 2.28, 1.14, 3.57],\n",
       "       [2.34, 2.97, 2.61, 0.5 , 0.3 , 0.26, 0.63, 1.02, 0.2 , 2.71],\n",
       "       [0.67, 1.18, 1.68, 2.7 , 1.95, 2.12, 2.72, 2.37, 1.18, 2.75],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.around(means, decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
